{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce75dd02-0c7b-40cc-930f-3b45f82ca080",
   "metadata": {},
   "source": [
    "Szöveges válaszokat tartalmazo excelek tokenizálása és lemmatizlása HuSpaCy segítségével."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f281d6-bdfc-4beb-a53d-64542e2e2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"hu_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a8a52-8f44-40f0-a8f7-dd917207783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bb14e-cebc-458b-99ce-5a77c624890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizáló függvény létrehozása: kisbetűsít és szótövesít. Úgy döntöttem, hogy a számokat egyelőre nem távolítom el, mert még hasznosak lehetnek a későbbiekben.\n",
    "\n",
    "def lemmatizal(szoveg):\n",
    "    if not isinstance(szoveg, str):\n",
    "        return \"\"\n",
    "    doc = nlp(szoveg)\n",
    "    lemmak = [token.lemma_.lower() for token in doc if not token.is_space]\n",
    "    return \" \".join(lemmak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d77810-8f2e-4808-b5e2-e8f6455ee784",
   "metadata": {},
   "source": [
    "50 soronként haladtam végig az adatbázisokon és közben mentettem az eredményeket. Ezt azért gondoltam szükségesnek, mert elég hosszú ideig fut a ciklus, nem szerettem volna előröl kezdeni, ha valami miatt elakad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7595f62-3774-41ee-bd5e-06b4dd62fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 89 pályázatot tartalmazó tábla lemmatizálása\n",
    "\n",
    "input_fajl = \"CERV-F3-2024_89db_text.xlsx\"\n",
    "df = pd.read_excel(input_fajl)\n",
    "\n",
    "chunk_meret = 50  # hány sort dolgozzon fel egyszerre\n",
    "ossz_sor = len(df)\n",
    "\n",
    "# feldolgozás ciklusban\n",
    "feldolgozott_df = pd.DataFrame()\n",
    "\n",
    "for start in range(0, ossz_sor, chunk_meret):\n",
    "    end = min(start + chunk_meret, ossz_sor)\n",
    "    print(f\"➡️ Feldolgozás: sorok {start + 1}–{end} / {ossz_sor}\")\n",
    "    \n",
    "    df_chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # minden oszlop feldolgozása (minden sor minden cellája)\n",
    "    for col in df.columns:\n",
    "        df_chunk[col] = df_chunk[col].apply(lemmatizal)\n",
    "    \n",
    "    # hozzáfűzés a fő táblázathoz\n",
    "    feldolgozott_df = pd.concat([feldolgozott_df, df_chunk], ignore_index=True)\n",
    "    \n",
    "    # mentés közben is\n",
    "    feldolgozott_df.to_excel(\"CERV-F3-2024_89db_text_lemmatizalt.xlsx\", index=False)\n",
    "    \n",
    "    # szünet a stabilitás miatt\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Kész! A teljes lemmatizált táblázat mentve: CERV-F3-2024_89db_text_lemmatizalt.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29bcef-4e02-4996-a361-f62f2549c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 93 pályázatot tartalmazó tábla lemmatizálása\n",
    "\n",
    "input_fajl = \"CERV-P-2023_93db_text.xlsx\"\n",
    "df = pd.read_excel(input_fajl)\n",
    "\n",
    "chunk_meret = 50  # hány sort dolgozzon fel egyszerre\n",
    "ossz_sor = len(df)\n",
    "\n",
    "# feldolgozás ciklusban\n",
    "feldolgozott_df = pd.DataFrame()\n",
    "\n",
    "for start in range(0, ossz_sor, chunk_meret):\n",
    "    end = min(start + chunk_meret, ossz_sor)\n",
    "    print(f\"➡️ Feldolgozás: sorok {start + 1}–{end} / {ossz_sor}\")\n",
    "    \n",
    "    df_chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # minden oszlop feldolgozása (minden sor minden cellája)\n",
    "    for col in df.columns:\n",
    "        df_chunk[col] = df_chunk[col].apply(lemmatizal)\n",
    "    \n",
    "    # hozzáfűzés a fő táblázathoz\n",
    "    feldolgozott_df = pd.concat([feldolgozott_df, df_chunk], ignore_index=True)\n",
    "    \n",
    "    # mentés közben is\n",
    "    feldolgozott_df.to_excel(\"CERV-P-2023_93db_text_lemmatizalt.xlsx\", index=False)\n",
    "    \n",
    "    # szünet a stabilitás miatt\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Kész! A teljes lemmatizált táblázat mentve: CERV-P-2023_93db_text_lemmatizalt.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06470f-0902-4642-9ace-dde343e28b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 259 pályázatot tartalmazó tábla lemmatizálása\n",
    "\n",
    "input_fajl = \"F_2023_FK02_259db_text.xlsx\"\n",
    "df = pd.read_excel(input_fajl)\n",
    "\n",
    "chunk_meret = 50  # hány sort dolgozzon fel egyszerre\n",
    "ossz_sor = len(df)\n",
    "\n",
    "# feldolgozás ciklusban\n",
    "feldolgozott_df = pd.DataFrame()\n",
    "\n",
    "for start in range(0, ossz_sor, chunk_meret):\n",
    "    end = min(start + chunk_meret, ossz_sor)\n",
    "    print(f\"➡️ Feldolgozás: sorok {start + 1}–{end} / {ossz_sor}\")\n",
    "    \n",
    "    df_chunk = df.iloc[start:end].copy()\n",
    "    \n",
    "    # minden oszlop feldolgozása (minden sor minden cellája)\n",
    "    for col in df.columns:\n",
    "        df_chunk[col] = df_chunk[col].apply(lemmatizal)\n",
    "    \n",
    "    # hozzáfűzés a fő táblázathoz\n",
    "    feldolgozott_df = pd.concat([feldolgozott_df, df_chunk], ignore_index=True)\n",
    "    \n",
    "    # mentés közben is\n",
    "    feldolgozott_df.to_excel(\"F_2023_FK02_259db_text_lemmatizalt.xlsx\", index=False)\n",
    "    \n",
    "    # szünet a stabilitás miatt\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Kész! A teljes lemmatizált táblázat mentve: CF_2023_FK02_259db_text_lemmatizalt.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
